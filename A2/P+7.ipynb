{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyODPwyeQ+lvtsGQX8frfAbw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PinknMatter/CART498-GenAI/blob/main/A2/P%2B7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "def p_plus_x(lines, model_name='gpt2', p=7):\n",
        "    \"\"\"\n",
        "    Removes the last word of each line, then uses GPT-2 to predict the\n",
        "    next word. Picks the p-th most likely word from GPT-2's distribution\n",
        "    and appends it to the line.\n",
        "\n",
        "    Args:\n",
        "        lines (list): List of strings, each treated as one line.\n",
        "        model_name (str): The GPT-2 model to use.\n",
        "        p (int): Which probability rank to choose (1 = most likely, etc.).\n",
        "\n",
        "    Returns:\n",
        "        list: List of new lines with the replaced word.\n",
        "    \"\"\"\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "    model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "    model.eval()\n",
        "\n",
        "    new_lines = []\n",
        "    for line in lines:\n",
        "        words = line.strip().split()\n",
        "        if not words:\n",
        "            new_lines.append(line)\n",
        "            continue\n",
        "\n",
        "        partial_line = \" \".join(words[:-1])\n",
        "        input_ids = tokenizer.encode(partial_line, return_tensors='pt')\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(input_ids)\n",
        "            next_token_logits = outputs.logits[0, -1, :]\n",
        "\n",
        "        probs = torch.softmax(next_token_logits, dim=-1)\n",
        "        sorted_probs, sorted_indices = torch.sort(probs, descending=True)\n",
        "\n",
        "        if (p - 1) < len(sorted_indices):\n",
        "            chosen_token_id = sorted_indices[p - 1].item()\n",
        "        else:\n",
        "            chosen_token_id = sorted_indices[-1].item()\n",
        "\n",
        "        chosen_token = tokenizer.decode([chosen_token_id]).strip()\n",
        "        new_line = partial_line + \" \" + chosen_token\n",
        "        new_lines.append(new_line)\n",
        "\n",
        "    return new_lines"
      ],
      "metadata": {
        "id": "8ll3DPyuABQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lines = [\n",
        "    \"One must have a mind of winter\",\n",
        "    \"To regard the frost and the boughs\",\n",
        "    \"Of the pine-trees crusted with snow;\",\n",
        "    \"And have been cold a long time\",\n",
        "    \"To behold the junipers shagged with ice,\",\n",
        "    \"The spruces rough in the distant glitter\",\n",
        "    \"Of the January sun; and not to think\",\n",
        "    \"Of any misery in the sound of the wind,\",\n",
        "    \"In the sound of a few leaves,\",\n",
        "    \"Which is the sound of the land\",\n",
        "    \"Full of the same wind\",\n",
        "    \"That is blowing in the same bare place\",\n",
        "    \"For the listener, who listens in the snow,\",\n",
        "    \"And, nothing himself, beholds\",\n",
        "    \"Nothing that is not there and the nothing that is.\"\n",
        "]\n",
        "\n",
        "print(\"\\n--- Final Lines ---\")\n",
        "results_p1 = p_plus_x(lines, p=20)\n",
        "for i, r in enumerate(results_p1, 1):\n",
        "    print(r)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRyFA6iTBw0y",
        "outputId": "1d428837-f762-4508-e68d-e48b5d8494df"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Final Lines ---\n",
            "One must have a mind of steel\n",
            "To regard the frost and the darkness\n",
            "Of the pine-trees crusted with his\n",
            "And have been cold a long hard\n",
            "To behold the junipers shagged with two\n",
            "The spruces rough in the distant sun\n",
            "Of the January sun; and not to give\n",
            "Of any misery in the sound of the car\n",
            "In the sound of a few ,\n",
            "Which is the sound of the phone\n",
            "Full of the same weight\n",
            "That is blowing in the same bare skin\n",
            "For the listener, who listens in the usual\n",
            "And, nothing himself, only\n",
            "Nothing that is not there and the nothing that remains\n"
          ]
        }
      ]
    }
  ]
}